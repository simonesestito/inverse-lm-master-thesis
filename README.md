# Inverse Language Modeling for Robust and Grounded LLMs

<p align="center">
    <b>Master's Degree Thesis in Computer Science</b>
    <br>
    <i>A causal model looks ahead, but only its gradients disclose the pasts that might have built that future.</i>
</p>

The current landscape of defensive mechanisms for LLMs is fragmented and underdeveloped, unlike prior work on classifiers.
To further promote adversarial robustness in LLMs, we propose Inverse Language Modeling (ILM), a unified framework that simultaneously:
1) improves the robustness of LLMs to input perturbations, and, at the same time,
2) enables native grounding by inverting model outputs to identify potentially toxic or unsafe input triggers.

ILM transforms LLMs from static generators into analyzable and robust systems, potentially helping RED teaming.

ILM can lay the foundation for next-generation LLMs that are not only robust and grounded but also fundamentally more controllable and trustworthy.

**Keywords:** Artificial Intelligence Safety, Large Language Models, Robustness, Adversarial Attacks, Inverse Problems

<div>
    <a href="https://arxiv.org/abs/2510.01929">
        <img src=".github/assets/arxiv-button.svg" height="80">
    </a>
    <a href="https://raw.githubusercontent.com/simonesestito/inverse-lm-master-thesis/main/thesis.pdf">
        <img src=".github/assets/thesis-button.svg" height="80">
    </a>
    <a href="https://raw.githubusercontent.com/simonesestito/inverse-lm-master-thesis/main/presentation.pdf">
        <img src=".github/assets/presentation-button.svg" height="80">
    </a>
</div>

<div>
    <a href="https://omnai.di.uniroma1.it/">
        <img src=".github/assets/omnai.png" height="70">
    </a>
    <a href="https://www.uniroma1.it/en/pagina-strutturale/home">
        <img src=".github/assets/sapienza.png" height="80">
    </a>
    <img src=".github/assets/nextgeneu-logo.png" height="60">
</div>


---

This repository contains the LaTeX source code of:
- Master Thesis
- ArXiv preprint
- Thesis Presentation and a Seminar for a Natural Language Processing university class

The source code for the experiment is available at:
https://github.com/davegabe/pag-llm

For authenticity verification, all commits have been either done via the GitHub web UI or signed with my own [GPG key](https://github.com/simonesestito.gpg).
